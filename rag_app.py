import os
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
from pinecone import Pinecone
from typing import List

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX = os.getenv("PINECONE_INDEX")

# --- å¿…é ˆç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯ ---
required_vars = {
    "OPENAI_API_KEY": OPENAI_API_KEY,
    "PINECONE_API_KEY": PINECONE_API_KEY,
    "PINECONE_INDEX": PINECONE_INDEX
}
missing = [k for k, v in required_vars.items() if not v]
if missing:
    raise EnvironmentError(f"ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {', '.join(missing)}")

# --- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– ---
client = OpenAI(api_key=OPENAI_API_KEY)
pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(PINECONE_INDEX)

# --- ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ ---
def get_embedding(text: str) -> List[float]:
    response = client.embeddings.create(
        model="text-embedding-ada-002",
        input=[text]
    )
    return response.data[0].embedding

# --- Pineconeã‹ã‚‰æ–‡è„ˆå–å¾— ---
def retrieve_context(query: str, namespace: str = "vocab", top_k: int = 3) -> str:
    xq = get_embedding(query)
    res = index.query(
        vector=xq,
        top_k=top_k,
        include_metadata=True,
        namespace=namespace
    )
    contexts = [match.metadata.get("text", "") for match in res.matches if match.metadata]
    return "\n".join(contexts)

# --- GPTã§å›ç­”ç”Ÿæˆ ---
def generate_answer(query: str, context: str) -> str:
    prompt = f"ä»¥ä¸‹ã®æ–‡è„ˆã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n\næ–‡è„ˆ:\n{context}\n\nè³ªå•: {query}"
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯è‹±æ¤œå¯¾ç­–ã‚¢ãƒ—ãƒªã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content

# --- namespaceç”Ÿæˆé–¢æ•°ï¼ˆç´šÃ—ãƒ¢ãƒ¼ãƒ‰ï¼‰---
def get_namespace(level: str, mode: str) -> str:
    level_map = {
        "5ç´š": "5", "4ç´š": "4", "3ç´š": "3", "æº–2ç´š": "pre2"
    }
    mode_map = {
        "èªå½™": "vocab", "é•·æ–‡": "passages", "ãƒªã‚¹ãƒ‹ãƒ³ã‚°": "listening"
    }
    return f"{mode_map[mode]}-{level_map[level]}"

# --- Streamlit UI ---
st.set_page_config(page_title="è‹±æ¤œRAGã‚¢ãƒ—ãƒª", layout="centered")
st.title("ğŸ“˜ è‹±æ¤œRAGã‚¢ãƒ—ãƒª MVP")
st.caption("ğŸ¯ èªå½™ãƒ»é•·æ–‡ãƒ»ãƒªã‚¹ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹è³ªå•ã«ã€æ–‡è„ˆä»˜ãã§å›ç­”ã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šç´šã¨ãƒ¢ãƒ¼ãƒ‰ã®é¸æŠï¼ˆDay-5 + Day-6ï¼‰---
level = st.sidebar.selectbox("ğŸ”½ è‹±æ¤œã®ç´šã‚’é¸æŠã—ã¦ãã ã•ã„", ["5ç´š", "4ç´š", "3ç´š", "æº–2ç´š"])
mode = st.sidebar.radio("ğŸ“š ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„", ["èªå½™", "é•·æ–‡", "ãƒªã‚¹ãƒ‹ãƒ³ã‚°"])

# --- æ¤œç´¢å¯¾è±¡ã®æ˜ç¤º ---
st.caption(f"ğŸ§­ ç¾åœ¨ã®æ¤œç´¢å¯¾è±¡ï¼š{level} Ã— {mode}")

# --- è³ªå•å…¥åŠ›æ¬„ ---
query = st.text_input("â“ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆæ—¥æœ¬èªï¼è‹±èªï¼‰")

# --- è³ªå•å±¥æ­´ã®åˆæœŸåŒ– ---
if "history" not in st.session_state:
    st.session_state.history = []

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
if query:
    with st.spinner("æ¤œç´¢ä¸­..."):
        try:
            namespace = get_namespace(level, mode)
            context = retrieve_context(query, namespace=namespace)
            answer = generate_answer(query, context)

            # å›ç­”è¡¨ç¤º
            st.markdown("### âœ… å›ç­”")
            st.write(answer)

            # å±¥æ­´ã«ä¿å­˜
            st.session_state.history.append((query, answer))
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{e}")

# --- è³ªå•å±¥æ­´è¡¨ç¤ºï¼ˆDay-5ï¼‰---
if st.session_state.history:
    with st.expander("ğŸ•“ è³ªå•å±¥æ­´"):
        for i, (q, a) in enumerate(reversed(st.session_state.history), 1):
            st.markdown(f"**Q{i}:** {q}")
            st.markdown(f"**A{i}:** {a}")
